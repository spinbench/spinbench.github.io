<!DOCTYPE html>
<html>
<head>
    <meta charset="utf-8">
    <title>SPIN-Bench: Connect Four</title>
    
    <!-- Reuse styles from template -->
    <link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro" rel="stylesheet">
    <link rel="stylesheet" href="../../static/css/bulma.min.css">
    <link rel="stylesheet" href="../../static/css/fontawesome.all.min.css">

    <!-- Add Prism.js for syntax highlighting -->
    <script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/prism.min.js"></script>
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css">
    
    <!-- Custom CSS -->
    <style>
        body {
            font-family: 'Noto Sans', sans-serif;
            line-height: 1.6;
            color: #333;
            background-color: #f5f7fa;
            padding: 20px;
        }
        .container {
            max-width: 1200px;
            margin: 0 auto;
            background-color: white;
            padding: 30px;
            border-radius: 10px;
            box-shadow: 0 0 10px rgba(0, 0, 0, 0.1);
        }
        h1, h2, h3, h4 {
            font-family: 'Google Sans', sans-serif;
            margin-top: 20px;
            margin-bottom: 15px;
        }
        h1 {
            font-size: 2.4rem;
            text-align: center;
            color: #333;
            margin-bottom: 30px;
        }
        h2 {
            font-size: 1.8rem;
            color: #2c3e50;
            border-bottom: 2px solid #eaeaea;
            padding-bottom: 10px;
        }
        .top-sections-wrapper {
            display: flex;
            flex-wrap: wrap;
            gap: 20px;
        }
        .game-intro-section,
        .game-setting-section {
            flex: 1;
            min-width: 320px;
            padding: 0 15px;
            margin: 0;
            border-radius: 8px;
            background-color: #fff;
            box-shadow: 0 2px 5px rgba(0, 0, 0, 0.1);
        }
        .game-intro-section {
            background-color: #f0f8ff;
        }
        .game-setting-section {
            background-color: #f5fffa;
        }
        .game-intro-badge,
        .game-setting-badge {
            display: inline-block;
            padding: 8px 15px;
            border-radius: 8px;
            color: white;
            font-weight: bold;
            margin-bottom: 15px;
        }
        .game-intro-badge {
            background-color: #3498db;
        }
        .game-setting-badge {
            background-color: #2ecc71;
        }
        .image-container {
            text-align: center;
            margin-bottom: 20px;
        }
        .image-container img {
            max-width: 100%;
            max-height: 300px;
            border-radius: 8px;
            box-shadow: 0 4px 8px rgba(0, 0, 0, 0.1);
        }
        .details {
            margin-top: 15px;
        }
        .details p {
            margin-bottom: 10px;
        }
        .steps-badge {
            display: inline-block;
            background-color: #9b59b6;
            color: white;
            padding: 8px 15px;
            border-radius: 6px;
            font-weight: bold;
        }
        .button-legend {
            display: flex;
            justify-content: center;
            margin-bottom: 20px;
            background-color: #f8f9fa;
            padding: 10px;
            border-radius: 8px;
        }
        .legend-item {
            display: flex;
            align-items: center;
            margin-right: 20px;
        }
        .legend-dot {
            width: 15px;
            height: 15px;
            border-radius: 50%;
            display: inline-block;
            margin-right: 5px;
        }
        .legend-dot.llm-solver {
            background-color: #3498db;
        }
        .legend-dot.llm-llm {
            background-color: #e74c3c;
        }
        .legend-dot.metrics {
            background-color: #f39c12;
        }
        .legend-text {
            font-size: 0.9rem;
            margin-right: 15px;
        }
        .steps-container {
            display: flex;
            background-color: #fff;
            border-radius: 8px;
            box-shadow: 0 2px 5px rgba(0, 0, 0, 0.1);
            overflow: hidden;
        }
        .steps-buttons {
            flex: 0 0 300px;
            background-color: #f5f7fa;
            padding: 20px;
            border-right: 1px solid #eaeaea;
        }
        .step-button {
            display: block;
            width: 100%;
            text-align: left;
            padding: 10px;
            margin-bottom: 10px;
            border: none;
            border-radius: 4px;
            background-color: #f8f9fa;
            cursor: pointer;
            transition: all 0.2s;
        }
        .step-button:hover {
            background-color: #e9ecef;
        }
        .step-button.active {
            background-color: #007bff;
            color: white;
        }
        .step-button.llm-solver {
            border-left: 5px solid #3498db;
        }
        .step-button.llm-llm {
            border-left: 5px solid #e74c3c;
        }
        .step-button.metrics {
            border-left: 5px solid #f39c12;
        }
        .step-content {
            flex: 1;
            padding: 20px;
            overflow-y: auto;
            max-height: 600px;
        }
        .step-content h3 {
            margin-top: 0;
            color: #2c3e50;
        }
        .step-content p {
            margin-bottom: 15px;
        }
        .step-content ul, .step-content ol {
            margin-left: 20px;
            margin-bottom: 15px;
        }
        .step-content table {
            width: 100%;
            border-collapse: collapse;
            margin-bottom: 20px;
        }
        .step-content table th, 
        .step-content table td {
            padding: 10px;
            border: 1px solid #ddd;
            text-align: left;
        }
        .step-content table th {
            background-color: #f8f9fa;
        }
        .step-content table tr:nth-child(even) {
            background-color: #f8f9fa;
        }
        .performance-chart {
            width: 100%;
            height: 300px;
            background-color: #f8f9fa;
            margin-bottom: 20px;
            border-radius: 8px;
            display: flex;
            justify-content: center;
            align-items: center;
            text-align: center;
        }
        .connect-four-grid {
            display: grid;
            grid-template-columns: repeat(7, 50px);
            grid-template-rows: repeat(6, 50px);
            gap: 5px;
            margin: 30px auto;
            width: 400px;
            background-color: #2874A6;
            padding: 10px;
            border-radius: 8px;
        }
        .connect-four-cell {
            width: 50px;
            height: 50px;
            background-color: #f8f9fa;
            border-radius: 50%;
            display: flex;
            justify-content: center;
            align-items: center;
        }
        .cell-red {
            background-color: #e74c3c;
        }
        .cell-yellow {
            background-color: #f1c40f;
        }
        .model-comparison {
            display: flex;
            justify-content: space-between;
            margin-bottom: 20px;
        }
        .model-card {
            flex: 1;
            padding: 15px;
            border-radius: 8px;
            background-color: #f8f9fa;
            margin: 0 10px;
            text-align: center;
        }
        .model-card h4 {
            margin-top: 0;
            margin-bottom: 10px;
        }
        .model-card-highlight {
            background-color: #e8f4fd;
            border: 1px solid #bed6e3;
        }
        code {
            background-color: #f8f9fa;
            padding: 2px 5px;
            border-radius: 3px;
            font-family: monospace;
        }
    </style>

    <!-- Custom JS -->
    <script src="https://cdn.jsdelivr.net/npm/marked/marked.min.js"></script>
    <script src="../../static/js/example.js"></script>
</head>

<body>
    <div class="container">
        <h1>Connect Four: Competitive Game</h1>
        
        <!-- Wrap sections in new container -->
        <div class="top-sections-wrapper">
            <!-- Game Introduction Section -->
            <div class="game-intro-section">
                <h3 class="game-intro-badge">Game Introduction</h3>
                <div class="image-container">
                    <img src="../../trajectories/llmllm/cf/Claude-3.5-Haiku_Llama3.1:70b/18.png" alt="Connect Four game board" />
                </div>
                <div class="details">
                    <p><strong>Game:</strong> Connect Four</p>
                    <p><strong>Complexity:</strong> Medium (Intermediate level in SPIN-Bench)</p>
                    <p><strong>Description:</strong> A two-player strategy game played on a vertical grid with six rows and seven columns. Players take turns dropping colored discs into the grid, aiming to align four discs horizontally, vertically, or diagonally.</p>
                    <p><strong>Purpose:</strong> Evaluates LLMs' capacity for intermediate-level strategic reasoning and foresight.</p>
                </div>
            </div>
            
            <!-- Game Setting Section -->
            <div class="game-setting-section">
                <h3 class="game-setting-badge">Game Settings</h3>
                <div class="details">
                    <p><strong>Settings:</strong> Two primary configurations are used to evaluate LLM performance:</p>
                    <ol>
                        1. <strong>LLM-vs-Solver:</strong> LLMs play against a professional Connect Four solver that can determine optimal moves for any board state.
                        <br>
                        2. <strong>LLM-vs-LLM:</strong> Different LLM models compete against each other (14 models total, 91 game pairs, 10 games per pair, position switched after half).
                    </ol>
                    <br>
                    <p><strong>Evaluation Metrics:</strong></p>
                    <ul>
                        1. Internal Elo ratings (relative performance between models)<br>
                        2. Step-wise evaluation using solver-generated move scores<br>
                        3. Illegal Move Lost Rate (IML %)<br>
                        4. Illegal Moves per Total Turns (IMT %)<br>
                    </ul><br>
                    <p><strong>Models Evaluated:</strong> GPT-4o, Claude 3.5 Sonnet, o1, o1-preview, o1-mini, o3-mini, DeepSeek-R1, Llama3.3-70b, Claude 3.5 Haiku, Qwen2.5-72b, Llama3.1-70b, GPT-4o-mini, GPT-4-turbo, Llama3-70b, Mistral-7b, Llama3.2-3b, GPT-3.5-turbo</p>
                </div>
            </div>
        </div>

        <!-- Steps Section -->
        <h3 class="steps-badge">Game Setup and Metrics</h3>

        <div class="button-legend">
            <div class="legend-item">
                <span class="legend-dot llm-solver"></span>
                <span class="legend-text">LLM-vs-Solver</span>
                <span class="legend-dot llm-llm"></span>
                <span class="legend-text">LLM-vs-LLM</span>
                <span class="legend-dot metrics"></span>
                <span class="legend-text">Performance Metrics</span>
            </div>
        </div>

        <div class="steps-container">
            <div class="steps-buttons">
                <button class="step-button llm-solver" data-step="game-overview">Game Overview</button>
                <br>
                <button class="step-button llm-solver" data-step="llm-solver-setup">LLM-vs-Solver Setup</button>
                <br>
                <button class="step-button llm-llm" data-step="llm-llm-setup">LLM-vs-LLM Setup</button>
                <br>
                <button class="step-button metrics" data-step="elo-ratings">Elo Ratings</button>
                <button class="step-button metrics" data-step="illegal-moves">Illegal Move Analysis</button>
                <button class="step-button metrics" data-step="stepwise-evaluation">Step-wise Evaluation</button>
            </div>
            <div class="step-content">
                <!-- Default content -->
                <h3>Select a section to view details</h3>
                <p>Click on any button from the left panel to view detailed information about Connect Four game analysis in SPIN-Bench.</p>
            </div>
        </div>
    </div>

    <script>
        // Step content data
        let stepContentC4 = {
            'game-overview': `
                <h3>Connect Four Game in SPIN-Bench</h3>
                <p>Connect Four serves as an intermediate-level competitive game in SPIN-Bench, designed to evaluate more advanced strategic reasoning capabilities than Tic Tac Toe. The game combines elements of planning and foresight, requiring players to both create winning opportunities and block their opponent's moves.</p>
                
                <h4>Game Rules</h4>
                <ul>
                    <li>Two players take turns dropping colored discs into a vertical 6×7 grid</li>
                    <li>Discs fall to the lowest available position in the selected column</li>
                    <li>The first player to align four discs horizontally, vertically, or diagonally wins</li>
                    <li>If all 42 positions are filled without a winner, the game ends in a draw</li>
                </ul>
                
                <h4>Game Complexity</h4>
                <ul>
                    <li><strong>State space complexity:</strong> Approximately 4.5 × 10^12 possible board configurations</li>
                    <li><strong>Game tree complexity:</strong> Approximately 10^21 possible games</li>
                    <li><strong>Branching factor:</strong> Maximum of 7 (number of columns), decreases as columns fill</li>
                    <li><strong>Solved game:</strong> First player can force a win with perfect play</li>
                </ul>
                
                <div class="connect-four-grid">
                    <div class="connect-four-cell"></div>
                    <div class="connect-four-cell"></div>
                    <div class="connect-four-cell"></div>
                    <div class="connect-four-cell"></div>
                    <div class="connect-four-cell"></div>
                    <div class="connect-four-cell"></div>
                    <div class="connect-four-cell"></div>
                    
                    <div class="connect-four-cell"></div>
                    <div class="connect-four-cell"></div>
                    <div class="connect-four-cell"></div>
                    <div class="connect-four-cell"></div>
                    <div class="connect-four-cell"></div>
                    <div class="connect-four-cell"></div>
                    <div class="connect-four-cell"></div>
                    
                    <div class="connect-four-cell"></div>
                    <div class="connect-four-cell"></div>
                    <div class="connect-four-cell"></div>
                    <div class="connect-four-cell cell-red"></div>
                    <div class="connect-four-cell"></div>
                    <div class="connect-four-cell"></div>
                    <div class="connect-four-cell"></div>
                    
                    <div class="connect-four-cell"></div>
                    <div class="connect-four-cell"></div>
                    <div class="connect-four-cell cell-yellow"></div>
                    <div class="connect-four-cell cell-red"></div>
                    <div class="connect-four-cell cell-yellow"></div>
                    <div class="connect-four-cell"></div>
                    <div class="connect-four-cell"></div>
                    
                    <div class="connect-four-cell"></div>
                    <div class="connect-four-cell cell-yellow"></div>
                    <div class="connect-four-cell cell-red"></div>
                    <div class="connect-four-cell cell-red"></div>
                    <div class="connect-four-cell cell-yellow"></div>
                    <div class="connect-four-cell"></div>
                    <div class="connect-four-cell"></div>
                    
                    <div class="connect-four-cell cell-yellow"></div>
                    <div class="connect-four-cell cell-red"></div>
                    <div class="connect-four-cell cell-yellow"></div>
                    <div class="connect-four-cell cell-red"></div>
                    <div class="connect-four-cell cell-yellow"></div>
                    <div class="connect-four-cell cell-red"></div>
                    <div class="connect-four-cell"></div>
                </div>
                
                <p>Connect Four challenges LLMs to demonstrate more sophisticated planning abilities:</p>
                <ul>
                    <li>Looking ahead multiple moves to identify winning sequences</li>
                    <li>Recognizing and blocking opponent's threats</li>
                    <li>Understanding gravity constraints (pieces fall to the bottom)</li>
                    <li>Creating multiple simultaneous threats (forks)</li>
                    <li>Evaluating positions with more complex strategic patterns</li>
                </ul>
            `,
            'llm-solver-setup': `
                <h3>LLM-vs-Solver Setup</h3>
                <p>In this evaluation setting, language models play against a professional Connect Four solver that can determine optimal moves for any board state. This provides a standardized benchmark to assess LLM performance against mathematically optimal play.</p>
                
                <h4>Solver Implementation</h4>
                <p>The Connect Four solver:</p>
                <ul>
                    <li>Implements a perfect play algorithm that has solved the game</li>
                    <li>Can evaluate any position and determine if it's a win, loss, or draw with perfect play</li>
                    <li>Identifies the optimal move at each step and its associated value</li>
                    <li>Knows that the first player (red) can force a win with perfect play</li>
                    <li>Always chooses the move that leads to the best outcome assuming optimal play from both sides</li>
                </ul>
                
                <h4>Evaluation Protocol</h4>
                <ul>
                    <li>Each LLM plays multiple games against the solver</li>
                    <li>LLMs alternate between playing as first player and second player</li>
                    <li>Legal moves (non-filled columns) are provided to the LLM at each turn</li>
                    <li>Game outcomes (win/loss/draw) are recorded</li>
                    <li>Move quality is assessed by comparing LLM moves to optimal solver moves</li>
                    <li>Illegal moves are tracked and counted</li>
                </ul>
                
                <h4>Models Evaluated</h4>
                <div class="model-comparison">
                    <div class="model-card">
                        <h4>Open Models</h4>
                        <ul>
                            <li>DeepSeek-R1</li>
                            <li>Llama3.3-70b</li>
                            <li>Llama3.2-3b</li>
                            <li>Llama3.1-70b</li>
                            <li>Llama3-70b</li>
                            <li>Qwen2.5-72b</li>
                        </ul>
                    </div>
                    <div class="model-card">
                        <h4>OpenAI Models</h4>
                        <ul>
                            <li>o1</li>
                            <li>o1-mini</li>
                            <li>o3-mini</li>
                            <li>GPT-4o</li>
                            <li>GPT-4-turbo</li>
                            <li>GPT-4o-mini</li>
                            <li>GPT-3.5-turbo</li>
                        </ul>
                    </div>
                    <div class="model-card">
                        <h4>Anthropic Models</h4>
                        <ul>
                            <li>Claude 3.5 Sonnet</li>
                            <li>Claude 3.5 Haiku</li>
                        </ul>
                    </div>
                </div>
            `,
            'llm-llm-setup': `
                <h3>LLM-vs-LLM Setup</h3>
                <p>The LLM-vs-LLM evaluation setting pits different language models against each other to assess relative strategic capabilities in a competitive environment with higher complexity than Tic Tac Toe.</p>
                
                <h4>Evaluation Protocol</h4>
                <ul>
                    <li>14 models tested, forming 91 unique model pairs</li>
                    <li>10 games played for each pair (5 with each model playing first)</li>
                    <li>Players alternate positions after half of the competitions</li>
                    <li>No external guidance or move suggestions provided</li>
                    <li>Elo ratings calculated based on match outcomes</li>
                </ul>
                
                <h4>Tournament Structure</h4>
                <p>The round-robin tournament structure ensures each model faces every other model, controlling for position advantage by having each model play both as first and second player.</p>
                
                <h4>Human Baseline</h4>
                <p>To provide context for model performance, human players also participated in matches against the LLMs and participate in the leaderboard.</p>
                
                <h4>Analysis Focus</h4>
                <ul>
                    <li>Relative performance between different LLMs</li>
                    <li>Performance gap between open and closed-source models</li>
                    <li>Comparison to human players</li>
                    <li>Consistency of play and strategic understanding</li>
                    <li>Ability to plan multiple moves ahead</li>
                    <li>Correlation between model size/architecture and game performance</li>
                </ul>
            `,
            'elo-ratings': `
                <h3>Elo Ratings</h3>
                <p>Elo ratings provide a standardized way to measure relative performance across all models in the tournament. These internal Elo ratings are calculated based on match outcomes, with ratings updated after each game.</p>
                <p>Connect Four presents a more challenging strategic environment than Tic Tac Toe, requiring deeper planning and better pattern recognition. The Elo ratings in this game reflect a model's ability to think multiple moves ahead and recognize complex strategic patterns.</p>
            `,
            'illegal-moves': `
                <h3>Illegal Move Analysis</h3>
                <p>An important aspect of evaluating LLMs in game settings is assessing their ability to follow game rules consistently. This analysis tracks how often models make illegal moves despite being provided with the list of legal moves.</p>
                
                <h4>Illegal Move Metrics</h4>
                <ul>
                    <li><strong>Illegal Move Lost Rate (IML) (%):</strong> Percentage of games lost due to illegal moves</li>
                    <li><strong>Illegal Moves per Total Turns (IMT) (%):</strong> Percentage of all turns where illegal moves were made</li>
                </ul>
                
                <p>A game is considered lost if a model makes 10 consecutive illegal moves in a single turn.</p>
                
                <p>In Connect Four, the most common types of illegal moves observed were:</p>
                <ul>
                    <li>Attempting to place a disc in a column that is already full</li>
                    <li>Specifying column numbers outside the valid range (1-7)</li>
                    <li>Providing answers in inconsistent formats</li>
                </ul>
                
                <p>This analysis demonstrates that rule comprehension and adherence becomes more challenging as game complexity increases, serving as a valuable indicator of model quality and understanding.</p>
            `,
            'stepwise-evaluation': `
                <h3>Step-wise Evaluation</h3>
                <p>To assess the quality of each move generated by LLMs, we compare it against the optimal move derived from the Connect Four solver and then assign a top-k move index to the LLM's action. Then we investigate the frequency distribution of top move indices for different models to compare.</p>
                
                <p>Connect Four provides a more demanding test of planning ability than Tic Tac Toe, requiring models to:</p>
                <ul>
                    <li>Evaluate complex positions with many more possible future states</li>
                    <li>Identify non-obvious threats that may develop several moves in advance</li>
                    <li>Understand the impact of gravity constraints on future board states</li>
                    <li>Develop and execute multi-step winning strategies</li>
                </ul>
            `,
        };

        // Handle button clicks
        document.addEventListener('DOMContentLoaded', () => {
            document.querySelectorAll('.step-button').forEach(button => {
                button.addEventListener('click', () => {
                    // Toggle active state
                    document.querySelectorAll('.step-button').forEach(btn => {
                        btn.classList.remove('active');
                    });
                    button.classList.add('active');

                    // Show content
                    const stepId = button.dataset.step;
                    const contentDiv = document.querySelector('.step-content');
                    contentDiv.innerHTML = stepContentC4[stepId] || '<h3>Content coming soon...</h3><p>This section is under development. Please check back later.</p>';
                });
            });

            // Trigger first button click automatically
            const firstButton = document.querySelector('.step-button');
            if (firstButton) {
                firstButton.click();
            }
        });
    </script>
</body>
</html>